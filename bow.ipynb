{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cleaned(content):\n",
    "    # First remove inline JavaScript/CSS:\n",
    "    cleaned = re.sub(r\"(?is)<(script|style).*?>.*?(</\\1>)\", \"\", content)\n",
    "    # Then remove html comments. \n",
    "    cleaned = re.sub(r\"(?s)<!--(.*?)-->[\\n]?\", \"\", cleaned)\n",
    "    # Next remove the remaining tags:\n",
    "    cleaned = re.sub(r\"(?s)<.*?>\", \" \", cleaned)\n",
    "    # Finally deal with whitespace\n",
    "    cleaned = re.sub(r\"&nbsp;\", \" \", cleaned)\n",
    "    cleaned = re.sub(r\"^$\", \"\", cleaned)\n",
    "    cleaned = re.sub(\"''|,\", \"\", cleaned)\n",
    "    cleaned = re.sub(r\"  \", \" \", cleaned)\n",
    "    cleaned = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", cleaned)\n",
    "    cleaned = re.sub(r\"\\'s\", \" \\'s\", cleaned)\n",
    "    cleaned = re.sub(r\"\\'ve\", \" \\'ve\", cleaned)\n",
    "    cleaned = re.sub(r\"n\\'t\", \" n\\'t\", cleaned)\n",
    "    cleaned = re.sub(r\"\\'re\", \" \\'re\", cleaned)\n",
    "    cleaned = re.sub(r\"\\'d\", \" \\'d\", cleaned)\n",
    "    cleaned = re.sub(r\"\\'ll\", \" \\'ll\", cleaned)\n",
    "    cleaned = re.sub(r\",\", \" , \", cleaned)\n",
    "    cleaned = re.sub(r\"!\", \" ! \", cleaned)\n",
    "    cleaned = re.sub(r\"\\(\", \" \\( \", cleaned)\n",
    "    cleaned = re.sub(r\"\\)\", \" \\) \", cleaned)\n",
    "    cleaned = re.sub(r\"\\?\", \" \\? \", cleaned)\n",
    "    cleaned = re.sub(r\"\\s{2,}\", \" \", cleaned)\n",
    "    cleaned = re.sub(r\"\\d+\", \"\", cleaned)\n",
    "    cleaned = re.sub(r\"[\\r\\n]+\", \" \", cleaned)\n",
    "    return cleaned.strip().lower()\n",
    "\n",
    "    \n",
    "def proccess_message(text):\n",
    "    msg = email.message_from_string(text)\n",
    "    '''To get the content from email objects'''\n",
    "    parts = []\n",
    "    for part in msg.walk():\n",
    "        if part.get_content_type() == 'text/plain':\n",
    "            parts.append( part.get_payload() )\n",
    "    content = ''.join(parts)\n",
    "    return cleaned(content)\n",
    "\n",
    "def load_from_path(path):\n",
    "    data = []\n",
    "    def proccess_dir(glob_re_path, label):\n",
    "        res = []\n",
    "        for file_path in glob.glob(glob_re_path):\n",
    "            with open(file_path, 'r') as f:\n",
    "                res.append([label, proccess_message(f.read())])\n",
    "        return res\n",
    "    data += proccess_dir(path+'/ham/*.txt', 0)\n",
    "    data += proccess_dir(path+'/spam/*.txt', 1)\n",
    "    return data\n",
    "\n",
    "class BagOfWords(object):\n",
    "    def __init__(self, tokenize=None, normalize=True):\n",
    "        self._vocab = dict(UNK=0)\n",
    "        self.normalize = normalize\n",
    "        if tokenize == None:\n",
    "            tokenize = lambda w: w.split(' ')\n",
    "        self._tokenize = tokenize\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self._vocab.update(dict([(v, k + 1) for k, v in enumerate(set([word for d in X for word in self._tokenize(d)]))]))\n",
    "        print(\"fitted\")\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        data = []\n",
    "        for d in X:\n",
    "            res = np.zeros(len(self._vocab), dtype=np.float32)\n",
    "            for word in self._tokenize(d):\n",
    "                res[self.__get_word_index(word)] += 1\n",
    "            if self.normalize:\n",
    "                res = np.log(res + 1)\n",
    "            \n",
    "            data.append(res)\n",
    "        return np.array(data)\n",
    "    \n",
    "    def __get_word_index(self, word):\n",
    "        return self._vocab.get(word, 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(load_from_path('./raw'), columns=['label', 'message'])\n",
    "data = load_from_path('./raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitted\n"
     ]
    }
   ],
   "source": [
    "# words = [\"\"\"some word that would be splitted and it happened for me every time\"\"\".split(\" \"),\n",
    "#          \"\"\"some other thing that should be proccessed\"\"\".split(\" \")]\n",
    "# dict([(v, k+1) for k, v in enumerate(set([w for d in words for w in d]))])\n",
    "df = pd.DataFrame(data, columns=['label', 'content'])\n",
    "bow = BagOfWords()\n",
    "x = bow.fit_transform(df['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples shape 18860717664\n",
      "vocab len 139908\n"
     ]
    }
   ],
   "source": [
    "print 'samples shape', x.nbytes\n",
    "print 'vocab len', len(bow._vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
